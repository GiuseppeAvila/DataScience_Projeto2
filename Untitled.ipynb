{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciencia dos Dados - Star Wars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Nome: Daniel Gurgel Terra\n",
    ">   \n",
    ">Nome: Fernando Giuseppe Avila Beltramo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o ambiente no Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTAÇÕES\n",
    "\n",
    "import tweepy #twitter\n",
    "import math #op matematicas\n",
    "import os #op arquivos\n",
    "import pandas as pd #DataFrame, Series\n",
    "import json #manipulação de arquivos\n",
    "import re #expressões regulares\n",
    "import string #str\n",
    "from random import shuffle #random import embaralhar\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Autenticação no Twitter\n",
    "\n",
    "* Daniel Gurgel Terra : ***@LandWhale_Watch***\n",
    "* Fernando Giuseppe Avila Beltramo : ***@AttackHeli_ItMe***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza a API de uma conta qqr\n",
    "def Make_API(file_name):\n",
    "    \n",
    "    # JSON com as info das contas\n",
    "    with open(file_name) as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "    # Biblioteca de Auth <Não modificar>\n",
    "    auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "    auth.set_access_token( data['access_token'], data['access_token_secret'])\n",
    "    \n",
    "    # retorna a API\n",
    "    return tweepy.API(auth)\n",
    "\n",
    "# Conta @AttackHeli_ItMe\n",
    "API_AHIM = Make_API('AHIM_auth.pass')\n",
    "\n",
    "# Conta @LandWhale_Watch\n",
    "API_LWW = Make_API('LWW_auth.pass')\n",
    "\n",
    "API_list = [API_AHIM, API_LWW]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etapas do projeto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Função *Coleta_Tweet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta dos Tweets\n",
    "def Coleta_Tweet(procura, quantidade, linguagem):\n",
    "    \n",
    "    # Resultado\n",
    "    resultado = []\n",
    "    \n",
    "    api_value = 0\n",
    "    \n",
    "    # Para cada API das Contas:\n",
    "    for api in API_list:\n",
    "        \n",
    "        api_value += 1\n",
    "        \n",
    "        # Quantidade de tweets coletados nesta conta\n",
    "        contador = 0\n",
    "        \n",
    "        # Captura de um tweet que contenha a 'procura'\n",
    "        for tweet in tweepy.Cursor( api.search, q=procura, lang=linguagem, tweet_mode=\"extended\" ).items():\n",
    "            \n",
    "            # Caso a quantidade de tweets seja igual a quantidade pedida:\n",
    "            if contador == quantidade:\n",
    "                break\n",
    "            else:\n",
    "                frase = tweet.full_text.lower()\n",
    "               \n",
    "            # Se procura está em texto, bloqueia a repetição \n",
    "            if procura.lower() in frase:\n",
    "                if frase not in resultado:\n",
    "                    resultado.append(frase)\n",
    "                    \n",
    "            # Conta o tweet:\n",
    "            contador +=1\n",
    "            \n",
    "            # Barra de loading\n",
    "            Realizado = (contador/quantidade)*100\n",
    "            print(\"{0:.0f}% REALIZADO\".format(Realizado), end='\\r')\n",
    "            \n",
    "    # Embaralha o resultado (impedir tendência)\n",
    "    shuffle(resultado)\n",
    "    \n",
    "    # Retorna os tweets\n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### > Função *Limpa_Tweet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando os termos insignificantes de cada tweet, substitui por \"\"\n",
    "def Limpa_Tweet(lista_tweets, procura):\n",
    "    \n",
    "    # Remove Menções\n",
    "    lista_tweets = re.sub( \"@[^ ]*\", \"\", lista_tweets)\n",
    "    \n",
    "    # Remove Links\n",
    "    lista_tweets = re.sub( \"https(|s)/:\\/\\/[^ ]*\", \"\", lista_tweets)\n",
    "    \n",
    "    # Remove Pontuações\n",
    "    lista_tweets = re.sub( \"[\"+string.punctuation+\"]\", \"\", lista_tweets)\n",
    "    \n",
    "    # Remove Procura\n",
    "    lista_tweets = re.sub( procura.lower(), \"\", lista_tweets)\n",
    "    \n",
    "    # Lista Limpa\n",
    "    return lista_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Escolha de uma Marca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Marca e Quantidade de coleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marca\n",
    "procura = \"Star Wars\"\n",
    "\n",
    "# Quantidade de Tweets\n",
    "quantidade = 500\n",
    "\n",
    "# Linguagem\n",
    "linguagem = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Criando nome para o Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel gerados\n",
    "captura = 1\n",
    "\n",
    "# Verifica se no diretório há outro excel\n",
    "for file in os.listdir(\".\"):\n",
    "    if procura in file:\n",
    "        captura +=1\n",
    "\n",
    "# Nomeia o arquivo\n",
    "nome_arquivo = procura + \"_TREINO_\" + str(captura) + \".xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coletando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% REALIZADO\r"
     ]
    }
   ],
   "source": [
    "tabela = pd.DataFrame({\"tweets\": pd.Series(Coleta_Tweet(procura,quantidade,linguagem))})\n",
    "tabela.to_excel(nome_arquivo, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Considerando apenas as mensagens da planilha de Treinamento, ensine seu classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os excels avaliados em um DataFrame\n",
    "\n",
    "def criar_naive_bayes(excels, marca):\n",
    "    # Cria uma tabela incial com valores inciais\n",
    "    tabela_processada = pd.DataFrame({\"Tweets\": [\"\"], \"Categoria\": [\"\"],\n",
    "                                      \"Categoria atribuida automaticamente\": [\"\"]})\n",
    "    \n",
    "    # Junta todas as tabelas em uma\n",
    "    for tabela in excels:\n",
    "        tabela_processada = pd.concat([tabela_processada, pd.read_excel(tabela)], sort=False)\n",
    "    \n",
    "    # Tabela contento todas as tabelas exluindo a tabela inicial\n",
    "    tabela_processada = tabela_processada.iloc[1:]\n",
    "    \n",
    "    # Variave contendo todas as categorias selecionadas\n",
    "    categorias = set(tabela_processada[\"Categoria\"])\n",
    "    \n",
    "    # Dicionario resultado contendo a categoria como chave e a Sereis de probabilidade como valor\n",
    "    dict_resultado = {}\n",
    "    \n",
    "    for categoria in categorias:\n",
    "        # Separa os dados da tabela com o valor selecionado uma categoria\n",
    "        sub_tabela = tabela_processada[tabela_processada[\"Categoria\"] == categoria]\n",
    "        \n",
    "        # Juta todas os Tweets em uma string\n",
    "        mensagens = Limpa_Tweet(sub_tabela[\"Tweets\"].str.cat(), marca)\n",
    "        \n",
    "        # Cria uma series contendo todas as palavras das mensagens\n",
    "        series = pd.Series(mensagens.split())\n",
    "        \n",
    "        # Cria uma series contendo a probabilidade de cada palavra estar na categoria selecionada\n",
    "        dict_resultado[categoria] = series.value_counts(True)\n",
    "    \n",
    "    return dict_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para executar um teste dando novos tweets ultilizado um dicionanrio da naive_bayes\n",
    "\n",
    "def executar_teste(novos_tweets, dict_de_atribuicoes, marca):\n",
    "    # Lista contendo os resultados obtidos automaticamente para cada tweet novo\n",
    "    resultado = []\n",
    "    \n",
    "    #Separa cada tweet nos novos tweets\n",
    "    for tweet in novos_tweets:\n",
    "        \n",
    "        # Aramazena as probabilidades de cada categoria no dicionario\n",
    "        probabilidades = {}\n",
    "        \n",
    "        # Separa cada palavra no tweet\n",
    "        for palavra in Limpa_Tweet(mensagem, marca).split():\n",
    "            \n",
    "            # Para cada tipo de categoria\n",
    "            for tipo, probabilidade in dict_de_atribuicoes.items():\n",
    "                \n",
    "                # Verifica se a palavra se encontra em uma das probabilidades da categoria\n",
    "                if palavra in probabilidade:\n",
    "                    \n",
    "                    # Adiciona a probabilidade da palavra ao conjunto das probabilidades\n",
    "                    if tipo in probabilidades:\n",
    "                        probabilidades[tipo] = probabilidades[tipo] + probabilidade[palavra]\n",
    "                    else:\n",
    "                        probabilidades[tipo] = probabilidade[palavra]\n",
    "        \n",
    "        # Adiciona ao resultado o valor atribuido a esta mensagem\n",
    "        \n",
    "        # Não corespondeu a nenhuma categoria\n",
    "        if len(probabilidades) == 0:\n",
    "            resultado.append(-1)\n",
    "        else:\n",
    "            # Categoria identificado e adicionada\n",
    "            resultado.append(max(probabilidades, key=probabilidades.get))\n",
    "    \n",
    "    return resultado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
